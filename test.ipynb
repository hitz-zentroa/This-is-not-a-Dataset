{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:26:57.526603217Z",
     "start_time": "2024-02-23T09:26:57.507475243Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import get_dataloader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\",torch_dtype=torch.bfloat16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:05.371202514Z",
     "start_time": "2024-02-23T09:35:03.700722577Z"
    }
   },
   "id": "d57c117405344ac0",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.bfloat16"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:05.380822372Z",
     "start_time": "2024-02-23T09:35:05.372485862Z"
    }
   },
   "id": "b54d72b6fb645c0",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 90281 examples from test split\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = get_dataloader(tokenizer=tokenizer,split=\"test\",is_encoder_decoder=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:21.440444132Z",
     "start_time": "2024-02-23T09:35:07.022184288Z"
    }
   },
   "id": "ca7e1ced1d76f88c",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "for example in test_dataloader:\n",
    "    example = example\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:21.707246916Z",
     "start_time": "2024-02-23T09:35:21.439056298Z"
    }
   },
   "id": "4bd4323615810e4",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[   27,     7,     8,   826,  2493, 10998,    42, 10747,     7,    15,\n            58,    71,  2103,    19,  5871,    46,  7298,     3,  6443,   251,\n            81,    46,   605,     5,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1]]), 'labels': tensor([[10998,     1]]), 'loss_weight_mask': tensor([[1., 1.]])}"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:21.712308305Z",
     "start_time": "2024-02-23T09:35:21.705156515Z"
    }
   },
   "id": "ece0988f0bf9552",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['Is the following statement True or False? A notice is commonly an announcement containing information about an event.']"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(example['input_ids'],skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:21.751705329Z",
     "start_time": "2024-02-23T09:35:21.709928985Z"
    }
   },
   "id": "fa9647aad34f1ba5",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['True']"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(example['labels'],skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:21.752472648Z",
     "start_time": "2024-02-23T09:35:21.734204471Z"
    }
   },
   "id": "83852f7673a8c903",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:21.861996060Z",
     "start_time": "2024-02-23T09:35:21.745342847Z"
    }
   },
   "id": "83dd71183db8e58c",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.autocast(\n",
    "                        \"cuda\" if torch.cuda.is_available() else \"cpu\",dtype=model.dtype\n",
    "                    ):\n",
    "    encoder_output = model.get_encoder()(\n",
    "                                input_ids=example[\"input_ids\"].to(model.device),\n",
    "                                attention_mask=example[\"attention_mask\"].to(model.device),\n",
    "                            )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:45.425578368Z",
     "start_time": "2024-02-23T09:35:45.407956994Z"
    }
   },
   "id": "e7f511a731dc1b7c",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.autocast(\n",
    "                        \"cuda\" if torch.cuda.is_available() else \"cpu\",dtype=model.dtype\n",
    "                    ):\n",
    "    decoder_args = {\n",
    "                                \"attention_mask\": example[\"attention_mask\"],\n",
    "                                \"use_cache\": False,\n",
    "                                \"encoder_outputs\": encoder_output,\n",
    "                            }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:45.761181070Z",
     "start_time": "2024-02-23T09:35:45.753762834Z"
    }
   },
   "id": "443117ec0104e950",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.autocast(\n",
    "                        \"cuda\" if torch.cuda.is_available() else \"cpu\",dtype=model.dtype\n",
    "                    ):\n",
    "    gen_inputs = model.prepare_inputs_for_generation(\n",
    "                                input_ids=torch.tensor(\n",
    "                                    [[tokenizer.pad_token_id]] * len(example[\"input_ids\"])\n",
    "                                ).to(example[\"input_ids\"].device),\n",
    "                                **decoder_args,\n",
    "                            )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:46.123370890Z",
     "start_time": "2024-02-23T09:35:46.111242588Z"
    }
   },
   "id": "ced8fe02c475ade5",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'decoder_input_ids': tensor([[0]]),\n 'past_key_values': None,\n 'encoder_outputs': BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[-0.1025,  0.0762,  0.1279,  ..., -0.0052,  0.0305,  0.1602],\n          [-0.0286,  0.1104,  0.1436,  ...,  0.0845, -0.0486,  0.1465],\n          [-0.0154,  0.0003,  0.0105,  ...,  0.0022,  0.0018, -0.0055],\n          ...,\n          [-0.1196, -0.0376, -0.0500,  ...,  0.0408,  0.1543,  0.1680],\n          [ 0.0054, -0.1025,  0.0104,  ...,  0.0898,  0.0996, -0.0209],\n          [ 0.0084,  0.0066,  0.0146,  ...,  0.0024, -0.0024,  0.0004]]],\n        device='cuda:0', dtype=torch.bfloat16, grad_fn=<MulBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1]]),\n 'head_mask': None,\n 'decoder_head_mask': None,\n 'decoder_attention_mask': None,\n 'cross_attn_head_mask': None,\n 'use_cache': False}"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:35:47.053702800Z",
     "start_time": "2024-02-23T09:35:47.045818935Z"
    }
   },
   "id": "621e43c4f8e4490",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logits = model(\n",
    "                            **gen_inputs,\n",
    "                        ).logits\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:27:47.089820503Z",
     "start_time": "2024-02-23T09:27:47.049115567Z"
    }
   },
   "id": "bd5ac884c4e7dbe0",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 32128])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:27:48.494013473Z",
     "start_time": "2024-02-23T09:27:48.490192083Z"
    }
   },
   "id": "2d6dc477ce860093",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 32128])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits[:, -1, :]\n",
    "logits.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:27:48.855064423Z",
     "start_time": "2024-02-23T09:27:48.851288666Z"
    }
   },
   "id": "decaedc9c8debe83",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 32128])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.nn.functional.softmax(logits, dim=-1)\n",
    "logits.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:27:58.135110456Z",
     "start_time": "2024-02-23T09:27:58.117844557Z"
    }
   },
   "id": "9b180aec449a40bb",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10998]\n",
      "[10747, 7, 15]\n",
      "10998\n",
      "10747\n",
      "True\n",
      "Fal\n"
     ]
    }
   ],
   "source": [
    "true_tokens_ids = tokenizer.encode(\"True\", add_special_tokens=False)\n",
    "false_tokens_ids = tokenizer.encode(\"False\", add_special_tokens=False)\n",
    "print(true_tokens_ids)\n",
    "print(false_tokens_ids)\n",
    "yes_id = true_tokens_ids[0]\n",
    "no_id = false_tokens_ids[0]\n",
    "print(yes_id)\n",
    "print(no_id)\n",
    "print(tokenizer.decode([yes_id]))\n",
    "print(tokenizer.decode([no_id]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:28:51.995014297Z",
     "start_time": "2024-02-23T09:28:51.926899399Z"
    }
   },
   "id": "bac3c9b58ee132b7",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.8580, 0.1017]], grad_fn=<IndexBackward0>)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits[:, [yes_id, no_id]]\n",
    "logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:29:13.552094147Z",
     "start_time": "2024-02-23T09:29:13.503378062Z"
    }
   },
   "id": "b5189bb497b8c040",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.8940], grad_fn=<DivBackward0>)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:, 0] / (logits[:, 0] + logits[:, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:29:39.348673174Z",
     "start_time": "2024-02-23T09:29:39.303967137Z"
    }
   },
   "id": "608b7bdf5874fdb3",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bdbd8b914a92b4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
