#Model args
model_name_or_path: lmsys/vicuna-13b-v1.1 # we use v1.1 in the paper, but lmsys/vicuna-13b-v1.5 is the latest version
torch_dtype: "float32"
quantization: 4
predict_with_generate: false
per_device_eval_batch_size: 32
conversation_template: vicuna_v1.1

# dataset arguments
do_train: false
do_eval: false
do_predict: true
do_predict_full_dataset: true
max_seq_length: 512


# Output Dir
output_dir: results/zero-shot/vicuna-13b-v1.1


